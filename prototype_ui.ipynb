{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5ecb8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import re\n",
    "from cambrian import Dataset\n",
    "from SegGPT_inference.seggpt_inference import prepare_model\n",
    "from SegGPT_inference.seggpt_engine import inference_image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date and Time\n",
    "#Lawrance\n",
    "'''\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "#now = 2023-07-18 14:16:55.857082\n",
    "#date and time = 18/07/2023 14:16:55\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611eb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize Image Function \n",
    "#    - Used for prompt sending into model\n",
    "def resizeImg_(img):\n",
    "    res, hres = 448, 448\n",
    "    img = Image.fromarray(img).convert(\"RGB\")\n",
    "    img = img.resize((res, hres))\n",
    "    temp = io.BytesIO()\n",
    "    img.save(temp, format=\"WEBP\")\n",
    "    return base64.b64encode(temp.getvalue()).decode('ascii')\n",
    "\n",
    "def resizeImg(img):\n",
    "    res, hres = 448, 448\n",
    "    img = Image.fromarray(img).convert(\"RGB\")\n",
    "    img = img.resize((res, hres))\n",
    "    return img\n",
    "\n",
    "def resizeImgIo(img):\n",
    "    res, hres = 448, 448\n",
    "    img = Image.fromarray(img).convert(\"RGB\")\n",
    "    img = img.resize((res, hres))\n",
    "    temp = io.BytesIO()\n",
    "    img.save(temp, format=\"WEBP\")\n",
    "    return io.BytesIO(temp.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa229d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of Prompts and Prediction Function\n",
    "examples = [\n",
    "            ['./images/hmbb_1.jpg', './images/hmbb_2.jpg'],\n",
    "            ['./images/rainbow_1.jpg', './images/rainbow_2.jpg'],\n",
    "            ['./images/earth_1.jpg', './images/earth_2.jpg'],\n",
    "            ['./images/obj_1.jpg', './images/obj_2.jpg'],\n",
    "            ['./images/ydt_2.jpg', './images/ydt_1.jpg'],\n",
    "           ]\n",
    "examples_pred = [\n",
    "            ['./images/hmbb_3.jpg'],\n",
    "            ['./images/rainbow_3.jpg'],\n",
    "            ['./images/earth_3.jpg'],\n",
    "            ['./images/obj_3.jpg'],\n",
    "            ['./images/ydt_3.jpg'],\n",
    "           ]\n",
    "'''\n",
    "examples = [\n",
    "            ['./images/hmbb_1.jpg', './images/hmbb_2.jpg', './images/hmbb_3.jpg'],\n",
    "            ['./images/rainbow_1.jpg', './images/rainbow_2.jpg', './images/rainbow_3.jpg'],\n",
    "            ['./images/earth_1.jpg', './images/earth_2.jpg', './images/earth_3.jpg'],\n",
    "            ['./images/obj_1.jpg', './images/obj_2.jpg', './images/obj_3.jpg'],\n",
    "            ['./images/ydt_2.jpg', './images/ydt_1.jpg', './images/ydt_3.jpg'],\n",
    "           ]\n",
    "'''\n",
    "examples_video = [\n",
    "            ['./videos/horse-running.jpg', './videos/horse-running.mp4'],\n",
    "            ['./videos/a_man_is_surfing_3_30.jpg', './videos/a_man_is_surfing_3_30.mp4'],\n",
    "    ['./videos/a_car_is_moving_on_the_road_40.jpg', './videos/a_car_is_moving_on_the_road_40.mp4'],\n",
    "['./videos/jeep-moving.jpg', './videos/jeep-moving.mp4'],\n",
    "['./videos/child-riding_lego.jpg', './videos/child-riding_lego.mp4'],\n",
    "['./videos/a_man_in_parkour_100.jpg', './videos/a_man_in_parkour_100.mp4'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b74601",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#Load Model (When use ---> Un-comment every line)\n",
    "\n",
    "#device = \"cuda\"\n",
    "#model = prepare_model(\"SegGPT_inference/seggpt_vit_large.pth\", \"seggpt_vit_large_patch16_input896x448\", \"instance\").to(device)\n",
    "#print('Model loaded.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef0690",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy model function\n",
    "def demo_function2(prompt1,prompt2,prompt3,prompt4,prompt5,prompt6,prompt7,prompt8,prompt9,prompt10,\n",
    "                 img):\n",
    "    prompt_image_list = []\n",
    "    prompt_tgt_list = []\n",
    "    if prompt1:\n",
    "        prompt_image_list.append(resizeImg(prompt1[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt1[\"mask\"]))\n",
    "    if prompt2:\n",
    "        prompt_image_list.append(resizeImg(prompt2[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt2[\"mask\"]))\n",
    "    if prompt3:\n",
    "        prompt_image_list.append(resizeImg(prompt3[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt3[\"mask\"]))\n",
    "    if prompt4:\n",
    "        prompt_image_list.append(resizeImg(prompt4[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt4[\"mask\"]))\n",
    "    if prompt5:\n",
    "        prompt_image_list.append(resizeImg(prompt5[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt5[\"mask\"]))\n",
    "    if prompt6:\n",
    "        prompt_image_list.append(resizeImg(prompt6[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt6[\"mask\"]))\n",
    "    if prompt7:\n",
    "        prompt_image_list.append(resizeImg(prompt7[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt7[\"mask\"]))\n",
    "    if prompt8:\n",
    "        prompt_image_list.append(resizeImg(prompt8[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt8[\"mask\"]))\n",
    "    if prompt9:\n",
    "        prompt_image_list.append(resizeImg(prompt9[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt9[\"mask\"]))        \n",
    "    if prompt10:\n",
    "        prompt_image_list.append(resizeImg(prompt10[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt10[\"mask\"]))   \n",
    "        \n",
    "    #Un-Comment when use GPU and load model   \n",
    "    #output = inference_image_pil(model, device, resizeImg(img), prompt_image_list, prompt_tgt_list)\n",
    "    output = img\n",
    "    return output\n",
    "\n",
    "#Better way of sending in prompts(Error - list error)\n",
    "def demo_function(prompts, img):\n",
    "    prompt_image_list = []\n",
    "    prompt_tgt_list = []\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        if prompt is not None:\n",
    "            prompt_image_list.append(resizeImg(prompt[\"image\"]))\n",
    "            prompt_tgt_list.append(resizeImg(prompt[\"mask\"]))\n",
    "    \n",
    "    # Process the prompts and final image here and return the output image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea76654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other Functions\n",
    "#Function that evaluates the performance\n",
    "def evaluate_function(img):\n",
    "    #after evaluation\n",
    "    x=0.488\n",
    "    return x\n",
    "\n",
    "#Help with slider prompt\n",
    "def variable_outputs(x):\n",
    "    x = int(x)\n",
    "    return [gr.ImageMask.update(visible=True)]*x+ [gr.ImageMask.update(value= None, visible=False)]*(max_imagebox-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get user name and project\n",
    "\n",
    "def get_cookie_value(cookie_string, cookie_name):\n",
    "    pattern = cookie_name + r'=(.*?)(?:;|$)'\n",
    "    match = re.search(pattern, cookie_string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def get_user_name(request: gr.Request): #returns the user name\n",
    "    cookie_string = request.headers['cookie']\n",
    "    user_name = get_cookie_value(cookie_string, 'user')\n",
    "    user_name = base64.b64decode(user_name).decode('utf-8')\n",
    "    return user_name, user_name\n",
    "\n",
    "def get_projects(user_name):\n",
    "    print('user_name in get_projects', user_name)\n",
    "    url = \"http://cambrian-project-mgr-api-service.cambrian-platform/prjcfg/ProjectList_Owner_and_WhiteUser\"\n",
    "    params = {\n",
    "        \"request\": user_name,\n",
    "        \"filter_solution\": \"true\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    project_list = response.json().get('PRJ_LIST', [])\n",
    "    project_names_token_pair = [p.get('NAME', '') + ' - ' + p.get('TOKEN', '') for p in project_list]\n",
    "    project_names = [p.get('NAME', '') for p in project_list]\n",
    "    return gr.Dropdown.update(choices=project_names_token_pair), project_list\n",
    "\n",
    "def show_project_token(project_name_token):\n",
    "    token = project_name_token.split(' - ')[1]\n",
    "    return token\n",
    "def show_project_name(project_name_token):\n",
    "    token = project_name_token.split(' - ')[0]\n",
    "    return token\n",
    "\n",
    "def get_path(output_file): #output_file is gr.File variable\n",
    "    return str(output_file.name)  # Use .name to get the file path from the output_file object\n",
    "def dummy(project_name_token):\n",
    "    return gr.DataFrame(value = [[5,6],[7,8]], headers=['h','f'], Label = \"table\")\n",
    "\n",
    "project_token = os.environ['PROJECT_TOKEN']\n",
    "#user_name = 'gallon_shih'\n",
    "#ds = Dataset()\n",
    "#print(f'User name: {user_name}')\n",
    "print(f'Project token: {project_token}')\n",
    "#project token is given in show_project_token\n",
    "#user_name = user_name\n",
    "#show_project_token(project_dropdown)\n",
    "# save prompt\n",
    "\n",
    "def save_data(user_name, file_path, project_token, file_name,prompt_num,predict_img_num,performance_num,prompt_desc):\n",
    "    print(\"user name: \" + user_name)\n",
    "    print(\"file path: \" + file_path)\n",
    "    print(\"project_token: \" + project_token)\n",
    "    print(\"file_name: \" + file_name)\n",
    "\n",
    "    ds = Dataset()\n",
    "    ret = ds.add(\n",
    "                filename=file_path, #your f5 filepath in local\n",
    "                token=project_token,\n",
    "                name=file_name,\n",
    "                visible=\"private\",\n",
    "                meta={\n",
    "                    \"general\":{\n",
    "                        \"image_count\": {\n",
    "                            \"train\": prompt_num,\n",
    "                            \"validate\": 0,\n",
    "                            \"test\": predict_img_num\n",
    "                        },\n",
    "                        \"labeled_image_count\": prompt_num,\n",
    "                        \"unlabeled_image_count\": 0,\n",
    "                        \"sample_count\": { #same as image_count\n",
    "                            \"train\": prompt_num,\n",
    "                            \"validate\": 0,\n",
    "                            \"test\": predict_img_num\n",
    "                        },\n",
    "                        \"labeled_sample_count\": prompt_num, #same as labeled_image_count\n",
    "                        \"unlabeled_sample_count\": 0, #same as unlabeled_image_count\n",
    "                        \"description\": prompt_desc,\n",
    "                        \"project_token\": project_token,\n",
    "                        \"dataset_type\": [\n",
    "                            \"image\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"image\": {\n",
    "                        \"color_type\": \"Binary\",\n",
    "                        \"image_dataset_format\": \"Binary\",\n",
    "                        \"image_resolution\": {\n",
    "                            \"448x448\": prompt_num #your images size and count\n",
    "                        }\n",
    "                    },\n",
    "                    \"label\": {\n",
    "                        \"label_type\": [\n",
    "                            \"classification\",\n",
    "                            \"seggpt\" # custome label\n",
    "                            \"gradio_seggpt\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"misc\": {\n",
    "                        \"creator\": user_name, \n",
    "                        \"job_id\": 0,\n",
    "                        \"job_name\": \"\",\n",
    "                        \"resize\": \"none\"\n",
    "                    }\n",
    "                }\n",
    "    )\n",
    "\n",
    "def load_data(project_token):\n",
    "    ds = Dataset()\n",
    "    ret = ds.get_private_dataset(project_token)\n",
    "    dataset_details = []\n",
    "    for dataset_id, details in ret.items():\n",
    "        dataset_name = details['name']\n",
    "        dataset_owner = details['owner']\n",
    "        dataset_creator = details['metas'].get('creator', '')\n",
    "        dataset_created_time = details['versions'][0]['createdTime']\n",
    "        dataset_size = details['versions'][0]['size']\n",
    "        dataset_details.append({\n",
    "            'Dataset ID': dataset_id,\n",
    "            'Name': dataset_name,\n",
    "            'Owner': dataset_owner,\n",
    "            'Creator': dataset_creator,\n",
    "            'Created Time': dataset_created_time,\n",
    "            'Size': dataset_size,\n",
    "        })\n",
    "\n",
    "    return dataset_details\n",
    "\n",
    "def get_data(d_token,p_token):\n",
    "    ds = Dataset()\n",
    "    filepath = '../file.h5'\n",
    "    ret = ds.get(dataset_token= d_token , project_token= p_token, version=None, filename=filepath)\n",
    "    print(ret)\n",
    "\n",
    "def load_and_display(project_token):\n",
    "    dataset = load_data(project_token)\n",
    "    return create_table(dataset)\n",
    "\n",
    "def create_table(dataset):\n",
    "    table_headers = ['Dataset ID', 'Name', 'Owner', 'Creator', 'Created Time', 'Size']\n",
    "    return gr.DataFrame(dataset, headers=table_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70315cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package everything into a HDF file\n",
    "\n",
    "def package_images(prompt1, prompt2, prompt3, prompt4, prompt5,prompt6,prompt7,prompt8,prompt9,prompt10, output_file,\n",
    "                    predict_img,prediction_result, answer_mask, performance):\n",
    "    prompt_num = 0\n",
    "    predict_img_num = 0 \n",
    "    performance_num = 0\n",
    "    # Create a new HDF5 file\n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        # Create groups and store the image data\n",
    "        prompts = hf.create_group(\"prompts\")\n",
    "        test_set = hf.create_group(\"test_set\")\n",
    "        img = prompts.create_group(\"img\")\n",
    "        mask = prompts.create_group(\"mask\")\n",
    "        pred = test_set.create_group(\"pred\")\n",
    "        pred_ans = test_set.create_group(\"pred_ans\")\n",
    "        pred_img = pred.create_group(\"pred_img\")\n",
    "        pred_result_img = pred.create_group(\"pred_result_img\")\n",
    "        \n",
    "        #pred_result_mask = pred.create_group(\"pred_result_mask\")\n",
    "        print(\"start\")\n",
    "        if prompt1:\n",
    "            img.create_dataset('image_1', data=prompt1['image'])\n",
    "            mask.create_dataset('mask_1', data=prompt1['mask'])\n",
    "            print(\"file1\")\n",
    "            prompt_num+=1\n",
    "        if prompt2:    \n",
    "            img.create_dataset('image_2', data=prompt2['image'])\n",
    "            mask.create_dataset('mask_2', data=prompt2['mask'])\n",
    "            print(\"file2\")\n",
    "            prompt_num+=1\n",
    "        if prompt3:\n",
    "            img.create_dataset('image_3', data=prompt3['image'])\n",
    "            mask.create_dataset('mask_3', data=prompt3['mask'])\n",
    "            print(\"file3\")\n",
    "            prompt_num+=1\n",
    "        if prompt4:\n",
    "            img.create_dataset('image_4', data=prompt4['image'])\n",
    "            mask.create_dataset('mask_4', data=prompt4['mask'])\n",
    "            print(\"file4\")\n",
    "            prompt_num+=1\n",
    "        if prompt5:\n",
    "            img.create_dataset('image_5', data=prompt5['image'])\n",
    "            mask.create_dataset('mask_5', data=prompt5['mask'])\n",
    "            print(\"file5\")\n",
    "            prompt_num+=1\n",
    "        if prompt6:\n",
    "            img.create_dataset('image_6', data=prompt6['image'])\n",
    "            mask.create_dataset('mask_6', data=prompt6['mask'])\n",
    "            print(\"file6\")\n",
    "            prompt_num+=1\n",
    "        if prompt7:\n",
    "            img.create_dataset('image_7', data=prompt7['image'])\n",
    "            mask.create_dataset('mask_7', data=prompt7['mask'])\n",
    "            print(\"file7\")\n",
    "            prompt_num+=1\n",
    "        if prompt8:\n",
    "            img.create_dataset('image_8', data=prompt8['image'])\n",
    "            mask.create_dataset('mask_8', data=prompt8['mask'])\n",
    "            print(\"file8\")\n",
    "        if prompt9:\n",
    "            img.create_dataset('image_9', data=prompt9['image'])\n",
    "            mask.create_dataset('mask_9', data=prompt9['mask'])\n",
    "            print(\"file9\")\n",
    "            prompt_num+=1\n",
    "        if prompt10:\n",
    "            img.create_dataset('image_10', data=prompt10['image'])\n",
    "            mask.create_dataset('mask_10', data=prompt10['mask'])\n",
    "            print(\"file10\")\n",
    "            prompt_num+=1\n",
    "        if predict_img.any():\n",
    "            pred_img.create_dataset('pred_img_1', data = predict_img)\n",
    "            predict_img_num +=1\n",
    "            if performance:\n",
    "                pred_img.attrs['performance'] = performance\n",
    "                performance_num += 1 \n",
    "        if prediction_result.any():\n",
    "            print(\"hi\")\n",
    "            #pred_result_img.create_dataset('prediction_result_img', data= prediction_result['image'])\n",
    "            #pred_result_mask.create_dataset('prediction_result_mask', data= prediction_result['mask'])\n",
    "            pred_result_img.create_dataset('prediction_result_img', data= prediction_result)\n",
    "        if answer_mask.any():\n",
    "            print(\"hi\")\n",
    "            pred_ans.create_dataset('pred_ans', data = answer_mask)\n",
    "    return prompt_num, predict_img_num, performance_num\n",
    "\n",
    "\n",
    "#Helper Function for packaging and downloading\n",
    "def download_h5_file(prompt1, prompt2, prompt3, prompt4, prompt5,prompt6,prompt7,prompt8,prompt9,prompt10,predict_img,\n",
    "                        prediction_result, answer_mask, performance, prompt_name):\n",
    "    # Package the images into an HDF5 file\n",
    "    output_file = prompt_name + '.h5'\n",
    "    prompt_num, predict_img_num, performance_num = package_images(prompt1, prompt2, prompt3, prompt4, prompt5,prompt6,prompt7,prompt8,prompt9,prompt10, output_file, predict_img, prediction_result, answer_mask, performance)\n",
    "    return output_file, prompt_num, predict_img_num, performance_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369b737",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "demo_title = \"<div style = 'text-align: center;margin: 50px auto;padding: 20px;max-width: 1000px;background-color: #ffffff;box-shadow: 0px 0px 20px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 60px;font-weight: bold;color: #003366;text-shadow: 2px 2px 4px #cccccc;'>Inference-Based Defect Detection</h1>\\\n",
    "<div style = 'font-size: 24px;color: #333333;line-height: 1.6;max-width: 800px;margin: 0 auto;'> By implementing a defect detection AI model on the production line, we aim to streamline operations and improve quality control. Our goals include reducing missing and false reports, cutting down on human resources, and simplifying the overall working process.</div> \\\n",
    "<div style='font-size: 18px;color: #666666;line-height: 1.6;max-width: 800px;margin: 30px auto;'>UI allows users to upload images, labeled or unlabeled, perform defect detection, and report performance given the ground truth.</div> \\\n",
    "</div>\\\n",
    "\" \n",
    "upload_prompt_title = \"<div style = 'text-align: center;margin: 35px auto;padding: 20px;max-width: 800px;background-color: #ffffff;box-shadow: 0px 2px 6px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 35px;font-weight: bold;margin-bottom: 16px;color: #003366;'>Upload Prompt</h1>\\\n",
    "<div style = 'text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 16px;'> 1. Slide to choose the amount of prompt you want to upload </div> \\\n",
    "<div style='text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 20px;'>2. Label your prompts</div> \\\n",
    "</div>\\\n",
    "\"\n",
    "\n",
    "upload_predict_image_title = \"<div style = 'text-align: center;margin: 35px auto;padding: 20px;max-width: 800px;background-color: #ffffff;box-shadow: 0px 2px 6px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 35px;font-weight: bold;margin-bottom: 16px;color: #003366;'>Image Prediction and Evaluation</h1>\\\n",
    "<div style = 'text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 16px;'> 1. Upload your image for prediction </div> \\\n",
    "<div style='text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 20px;'>2. Upload the labeled mask and Evaluate Performance</div> \\\n",
    "</div>\\\n",
    "\"\n",
    "\n",
    "save_prompt_title = \"<div style = 'text-align: center;margin: 35px auto;padding: 20px;max-width: 800px;background-color: #ffffff;box-shadow: 0px 2px 6px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 35px;font-weight: bold;margin-bottom: 16px;color: #003366;'>Save Prompts</h1>\\\n",
    "<div style = 'text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 16px;'> 1. Enter your filename and save your prompt </div> \\\n",
    "<div style='text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 20px;'>2. Check your saved prompt in 'Saved Prompt' tab </div> \\\n",
    "</div>\\\n",
    "\"\n",
    "\n",
    "css = \"#prompt_block {max-width: 250px !important}\"\n",
    "project_info_list = []\n",
    "\n",
    "#Determine Maximum Amount of Prompts\n",
    "max_imagebox = 10\n",
    "\n",
    "saved_prompts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a61ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    user_name = gr.State('None')\n",
    "    project_options = gr.State([])\n",
    "    project_info_list = gr.State([])\n",
    "    project_token = gr.State('')\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale =7):\n",
    "            gr.Markdown(demo_title)\n",
    "        with gr.Column(scale =1):\n",
    "            user_name_display = gr.Text(label=\"user_name\")\n",
    "            project_dropdown = gr.Dropdown(project_options.value, label='Project Names', interactive=True)\n",
    "            \n",
    "            project_token_display = gr.Text(label=\"project_token\", visible = False)\n",
    "    demo.load(\n",
    "        fn=get_user_name,\n",
    "        inputs=[],\n",
    "        outputs=[user_name, user_name_display]\n",
    "    )\n",
    "    demo.load(\n",
    "        fn=get_projects,\n",
    "        inputs=[user_name],\n",
    "        outputs=[project_dropdown, project_info_list]\n",
    "    )\n",
    "\n",
    "    project_dropdown.change(\n",
    "        fn=show_project_token,\n",
    "        inputs=[project_dropdown],\n",
    "        outputs=[project_token_display]\n",
    "    )\n",
    "    \n",
    "    print(user_name)\n",
    "    print(project_info_list)\n",
    "\n",
    "    \n",
    "    gr.Markdown(\"<br>\\\n",
    "                <br>\\\n",
    "                \")\n",
    "    with gr.Tab(\"Prompting and Predicting\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\n",
    "                    upload_prompt_title\n",
    "                )\n",
    "                \n",
    "        with gr.Row():\n",
    "            slider = gr.Slider(1,max_imagebox, step = 1, value = 10, label = \"Amount of Prompts: \",scale=5)\n",
    "            prompt_button = gr.Button(value = \"Enter\",scale = 1)                \n",
    "        with gr.Row():    \n",
    "            imagebox = []\n",
    "            for i in range(max_imagebox):\n",
    "                \n",
    "                masked_image = gr.ImageMask(brush_radius=16, label = \"Prompt\", min_width = 350, scale = 1)\n",
    "                imagebox.append(masked_image)\n",
    "        with gr.Row():\n",
    "            gr.Markdown(upload_predict_image_title)        \n",
    "        with gr.Row():\n",
    "            '''\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# Upload Hdf5 File For Prediction\")\n",
    "                test_file = gr.File(Label = \"Upload Hdf5 File for Prediction\")\n",
    "                test_evaluation = gr.Button('Evaluate Performance')\n",
    "                test_performance = gr.Textbox(label = \"Performance(Dice Coefficient)\")   \n",
    "            '''\n",
    "            with gr.Column():\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"# Upload Photo for Prediction\")\n",
    "                        predict_img = gr.Image(shape=(240, 240),label = \"Predict Image\")\n",
    "                        predict_button = gr.Button('Predict')\n",
    "                        #clear_prompt_button = gr.ClearButton(imagebox, value = 'Clear All Prompt')\n",
    "                        #clear_image_button = gr.ClearButton(predict_img, value = 'Clear Predict Image')\n",
    "                    \n",
    "                        prediction_result = gr.Image(label = \"Prediction Result\", interactive = False)\n",
    "                        \n",
    "            \n",
    "            with gr.Column():\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"# <br>\\\n",
    "                                    \")\n",
    "                        answer_mask = gr.Image(label = \"Labeled Answer\")\n",
    "                        evaluate_button = gr.Button('Evaluate Performance')\n",
    "                        performance = gr.Textbox(label = \"Performance(Dice Coefficient)\")   \n",
    "        with gr.Row():\n",
    "            gr.Markdown(save_prompt_title)     \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale =5):\n",
    "                prompt_name = gr.Textbox(label = \"Prompt Name\")\n",
    "                prompt_desc = gr.Textbox(label = \"Description\")\n",
    "            with gr.Column(scale =1):\n",
    "                create_file_button = gr.Button('Create File')\n",
    "                save_file_button = gr.Button('Save Prompt')\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                output_file = gr.File(Label = \"Download HDF5\")\n",
    "\n",
    "            evaluate_button.click(evaluate_function, answer_mask, performance)      \n",
    "\n",
    "#SLIDE THEN CLICK TO CHANGE\n",
    "            prompt_button.click(variable_outputs, slider, imagebox)\n",
    "#SLIDE AND CHANGE IMMEDIATELY\n",
    "            #slider.change(variable_outputs, slider, imagebox)\n",
    "    \n",
    "    \n",
    "            print(imagebox)\n",
    "            #predict_button.click(demo_function, inputs= [imagebox, predict_img], outputs=prediction_result)\n",
    "            predict_button.click(demo_function2, inputs= [imagebox[0], imagebox[1],imagebox[2],imagebox[3],imagebox[4],imagebox[5],imagebox[6],imagebox[7],imagebox[8],imagebox[9], predict_img], outputs=[prediction_result])\n",
    "            #load_button.click()\n",
    "            prompt_num = gr.State('')\n",
    "            predict_img_num = gr.State('')\n",
    "            performance_num = gr.State('')\n",
    "            create_file_button.click(download_h5_file, inputs= [imagebox[0], imagebox[1],imagebox[2],imagebox[3],imagebox[4],imagebox[5],imagebox[6],imagebox[7],imagebox[8],imagebox[9],\n",
    "                                             predict_img,prediction_result, answer_mask, performance,prompt_name], outputs = [output_file,prompt_num,predict_img_num, performance_num])\n",
    "            file_path = gr.State('')\n",
    "            output_file.change(get_path, inputs = [output_file], outputs = file_path)  \n",
    "            save_file_button.click(save_data, inputs = [user_name, file_path, project_token_display, prompt_name,prompt_num,predict_img_num,performance_num,prompt_desc])\n",
    "            \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"<br>\\\n",
    "                <br>\\\n",
    "                \")\n",
    "                gr.Markdown(\"## Test Examples\")\n",
    "                gr.Examples(\n",
    "                    examples = examples,\n",
    "                    inputs = imagebox,\n",
    "                    cache_examples = False,\n",
    "                )\n",
    "                gr.Markdown(\"## Prediction Examples\")\n",
    "                gr.Examples(\n",
    "                    examples = examples_pred,\n",
    "                    inputs = predict_img,\n",
    "                    cache_examples = False,\n",
    "                )\n",
    "                \n",
    "\n",
    "                \n",
    "    with gr.Tab(\"Saved Prompt\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\n",
    "                            #title\n",
    "                            \"\"\"\n",
    "                            # THIS PAGE SHOWS ALL THE SAVED VERSION\n",
    "                            # Add a chart that shows entire chart\n",
    "                            # Add a dropdown\n",
    "                            \"\"\"\n",
    "                        ) \n",
    "                \n",
    "        #with gr.Row():\n",
    "            #table = gr.Dataframe(value = [[1,2],[3,4]], headers=['h','f'], Label = \"table\")\n",
    "            \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Text(visible=False)\n",
    "            with gr.Column():\n",
    "                load_button = gr.Button(\"Load Button\")\n",
    "            with gr.Column():\n",
    "                gr.Text(visible=False)\n",
    "\n",
    "        #gr.load(load_and_display, inputs =project_token_display, outputs = table)        \n",
    "        #load_button.click(function, inputs, outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch(enable_queue=True, server_name=\"0.0.0.0\",server_port=6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea30ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

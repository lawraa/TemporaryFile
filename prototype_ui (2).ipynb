{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab19f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import re\n",
    "from cambrian import Dataset\n",
    "from gradio import Tabs\n",
    "from SegGPT_inference.seggpt_inference import prepare_model\n",
    "from SegGPT_inference.seggpt_engine import inference_image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date and Time\n",
    "#Lawrance\n",
    "'''\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "#now = 2023-07-18 14:16:55.857082\n",
    "#date and time = 18/07/2023 14:16:55\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize Image Function \n",
    "#    - Used for prompt sending into model\n",
    "def resizeImg_(img):\n",
    "    res, hres = 448, 448\n",
    "    img = Image.fromarray(img).convert(\"RGB\")\n",
    "    img = img.resize((res, hres))\n",
    "    temp = io.BytesIO()\n",
    "    img.save(temp, format=\"WEBP\")\n",
    "    return base64.b64encode(temp.getvalue()).decode('ascii')\n",
    "\n",
    "def resizeImg(img):\n",
    "    res, hres = 448, 448\n",
    "    img = Image.fromarray(img).convert(\"RGB\")\n",
    "    img = img.resize((res, hres))\n",
    "    return img\n",
    "\n",
    "def resizeImgIo(img):\n",
    "    res, hres = 448, 448\n",
    "    img = Image.fromarray(img).convert(\"RGB\")\n",
    "    img = img.resize((res, hres))\n",
    "    temp = io.BytesIO()\n",
    "    img.save(temp, format=\"WEBP\")\n",
    "    return io.BytesIO(temp.getvalue())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of Prompts and Prediction Function\n",
    "examples = [\n",
    "            ['./images/hmbb_1.jpg', './images/hmbb_2.jpg'],\n",
    "            ['./images/rainbow_1.jpg', './images/rainbow_2.jpg'],\n",
    "            ['./images/earth_1.jpg', './images/earth_2.jpg'],\n",
    "            ['./images/obj_1.jpg', './images/obj_2.jpg'],\n",
    "            ['./images/ydt_2.jpg', './images/ydt_1.jpg'],\n",
    "           ]\n",
    "examples_pred = [\n",
    "            ['./images/hmbb_3.jpg'],\n",
    "            ['./images/rainbow_3.jpg'],\n",
    "            ['./images/earth_3.jpg'],\n",
    "            ['./images/obj_3.jpg'],\n",
    "            ['./images/ydt_3.jpg'],\n",
    "           ]\n",
    "'''\n",
    "examples = [\n",
    "            ['./images/hmbb_1.jpg', './images/hmbb_2.jpg', './images/hmbb_3.jpg'],\n",
    "            ['./images/rainbow_1.jpg', './images/rainbow_2.jpg', './images/rainbow_3.jpg'],\n",
    "            ['./images/earth_1.jpg', './images/earth_2.jpg', './images/earth_3.jpg'],\n",
    "            ['./images/obj_1.jpg', './images/obj_2.jpg', './images/obj_3.jpg'],\n",
    "            ['./images/ydt_2.jpg', './images/ydt_1.jpg', './images/ydt_3.jpg'],\n",
    "           ]\n",
    "'''\n",
    "examples_video = [\n",
    "            ['./videos/horse-running.jpg', './videos/horse-running.mp4'],\n",
    "            ['./videos/a_man_is_surfing_3_30.jpg', './videos/a_man_is_surfing_3_30.mp4'],\n",
    "    ['./videos/a_car_is_moving_on_the_road_40.jpg', './videos/a_car_is_moving_on_the_road_40.mp4'],\n",
    "['./videos/jeep-moving.jpg', './videos/jeep-moving.mp4'],\n",
    "['./videos/child-riding_lego.jpg', './videos/child-riding_lego.mp4'],\n",
    "['./videos/a_man_in_parkour_100.jpg', './videos/a_man_in_parkour_100.mp4'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65b1ab",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#Load Model (When use ---> Un-comment every line)\n",
    "\n",
    "#device = \"cuda\"\n",
    "#model = prepare_model(\"SegGPT_inference/seggpt_vit_large.pth\", \"seggpt_vit_large_patch16_input896x448\", \"instance\").to(device)\n",
    "#print('Model loaded.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16dfae4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a168bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy model function\n",
    "def demo_function2(prompt1,prompt2,prompt3,prompt4,prompt5,prompt6,prompt7,prompt8,prompt9,prompt10,\n",
    "                 img):\n",
    "    prompt_image_list = []\n",
    "    prompt_tgt_list = []\n",
    "    variable_type = type(prompt1[\"image\"])\n",
    "    variable_type2 = type(prompt1[\"mask\"])\n",
    "    # Print the type\n",
    "    print(variable_type)\n",
    "    print(variable_type2)\n",
    "    if prompt1:\n",
    "        print(\"start\")\n",
    "\n",
    "        prompt_image_list.append(resizeImg(prompt1[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt1[\"mask\"]))\n",
    "        \n",
    "    if prompt2:\n",
    "        prompt_image_list.append(resizeImg(prompt2[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt2[\"mask\"]))\n",
    "    if prompt3:\n",
    "        prompt_image_list.append(resizeImg(prompt3[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt3[\"mask\"]))\n",
    "    if prompt4:\n",
    "        prompt_image_list.append(resizeImg(prompt4[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt4[\"mask\"]))\n",
    "    if prompt5:\n",
    "        prompt_image_list.append(resizeImg(prompt5[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt5[\"mask\"]))\n",
    "    if prompt6:\n",
    "        prompt_image_list.append(resizeImg(prompt6[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt6[\"mask\"]))\n",
    "    if prompt7:\n",
    "        prompt_image_list.append(resizeImg(prompt7[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt7[\"mask\"]))\n",
    "    if prompt8:\n",
    "        prompt_image_list.append(resizeImg(prompt8[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt8[\"mask\"]))\n",
    "    if prompt9:\n",
    "        prompt_image_list.append(resizeImg(prompt9[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt9[\"mask\"]))        \n",
    "    if prompt10:\n",
    "        prompt_image_list.append(resizeImg(prompt10[\"image\"]))\n",
    "        prompt_tgt_list.append(resizeImg(prompt10[\"mask\"]))   \n",
    "        \n",
    "    #Un-Comment when use GPU and load model   \n",
    "    #output = inference_image_pil(model, device, resizeImg(img), prompt_image_list, prompt_tgt_list)\n",
    "    output = img\n",
    "    return output\n",
    "\n",
    "#Better way of sending in prompts(Error - list error)\n",
    "def demo_function(prompts, img):\n",
    "    prompt_image_list = []\n",
    "    prompt_tgt_list = []\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        if prompt is not None:\n",
    "            prompt_image_list.append(resizeImg(prompt[\"image\"]))\n",
    "            prompt_tgt_list.append(resizeImg(prompt[\"mask\"]))\n",
    "    \n",
    "    # Process the prompts and final image here and return the output image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other Functions\n",
    "#Function that evaluates the performance\n",
    "def evaluate_function(img):\n",
    "    #after evaluation\n",
    "    x=0.488\n",
    "    return x\n",
    "\n",
    "#Help with slider prompt\n",
    "def variable_outputs(x):\n",
    "    x = int(x)\n",
    "    return [gr.ImageMask.update(visible=True)]*x+ [gr.ImageMask.update(value= None, visible=False)]*(max_imagebox-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb886fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get user name and project\n",
    "\n",
    "def get_cookie_value(cookie_string, cookie_name):\n",
    "    pattern = cookie_name + r'=(.*?)(?:;|$)'\n",
    "    match = re.search(pattern, cookie_string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def get_user_name(request: gr.Request): #returns the user name\n",
    "    cookie_string = request.headers['cookie']\n",
    "    user_name = get_cookie_value(cookie_string, 'user')\n",
    "    user_name = base64.b64decode(user_name).decode('utf-8')\n",
    "    return user_name, user_name\n",
    "\n",
    "def get_projects(user_name):\n",
    "    print('user_name in get_projects', user_name)\n",
    "    url = \"http://cambrian-project-mgr-api-service.cambrian-platform/prjcfg/ProjectList_Owner_and_WhiteUser\"\n",
    "    params = {\n",
    "        \"request\": user_name,\n",
    "        \"filter_solution\": \"true\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    project_list = response.json().get('PRJ_LIST', [])\n",
    "    project_names_token_pair = [p.get('NAME', '') + ' - ' + p.get('TOKEN', '') for p in project_list]\n",
    "    project_names = [p.get('NAME', '') for p in project_list]\n",
    "    return gr.Dropdown.update(choices=project_names_token_pair), project_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac14563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_dataset(p_token):\n",
    "    #LAWRANCE\n",
    "    print(\"show all dataset function\")\n",
    "    dataset = load_data(p_token)\n",
    "    name_list = []\n",
    "    for key, value in dataset.items():\n",
    "        name = value.get('name')\n",
    "        if name:\n",
    "            dataset_id = key\n",
    "            name_with_id = f\"{name} - {dataset_id}\"\n",
    "            #print(name_with_id)\n",
    "            name_list.append(name_with_id)    \n",
    "\n",
    "    return gr.Dropdown.update(choices=name_list)\n",
    "    \n",
    "    \n",
    "    #LAWRANCE\n",
    "def get_data(d_token,p_token):\n",
    "    ds = Dataset()\n",
    "    filepath = '../file.h5'\n",
    "    ret = ds.get(dataset_token= d_token , token = p_token, version=None, filename=filepath)\n",
    "    ret\n",
    "\n",
    "def show_project_token(project_name_token):\n",
    "    token = project_name_token.split(' - ')[1]\n",
    "    return token\n",
    "\n",
    "def show_dataset_token(dataset_name_token):\n",
    "    token = dataset_name_token.split(' - ')[1]\n",
    "    return token\n",
    "\n",
    "def show_project_name(project_name_token):\n",
    "    token = project_name_token.split(' - ')[0]\n",
    "    return token\n",
    "\n",
    "def get_path(output_file): #output_file is gr.File variable\n",
    "    return str(output_file.name)  # Use .name to get the file path from the output_file object\n",
    "\n",
    "\n",
    "project_token = os.environ['PROJECT_TOKEN']\n",
    "\n",
    "print(f'Project token: {project_token}')\n",
    "\n",
    "# save prompt\n",
    "\n",
    "def save_data(user_name, file_path, project_token, file_name,prompt_num,predict_img_num,performance_num,prompt_desc):\n",
    "    print(\"user name: \" + user_name)\n",
    "    print(\"file path: \" + file_path)\n",
    "    print(\"project_token: \" + project_token)\n",
    "    print(\"file_name: \" + file_name)\n",
    "\n",
    "    ds = Dataset()\n",
    "    ret = ds.add(\n",
    "                filename=file_path, #your f5 filepath in local\n",
    "                token=project_token,\n",
    "                name=file_name,\n",
    "                visible=\"private\",\n",
    "                meta={\n",
    "                    \"general\":{\n",
    "                        \"image_count\": {\n",
    "                            \"train\": prompt_num,\n",
    "                            \"validate\": 0,\n",
    "                            \"test\": predict_img_num\n",
    "                        },\n",
    "                        \"labeled_image_count\": prompt_num,\n",
    "                        \"unlabeled_image_count\": 0,\n",
    "                        \"sample_count\": { #same as image_count\n",
    "                            \"train\": prompt_num,\n",
    "                            \"validate\": 0,\n",
    "                            \"test\": predict_img_num\n",
    "                        },\n",
    "                        \"labeled_sample_count\": prompt_num, #same as labeled_image_count\n",
    "                        \"unlabeled_sample_count\": 0, #same as unlabeled_image_count\n",
    "                        \"description\": prompt_desc,\n",
    "                        \"project_token\": project_token,\n",
    "                        \"dataset_type\": [\n",
    "                            \"image\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"image\": {\n",
    "                        \"color_type\": \"Binary\",\n",
    "                        \"image_dataset_format\": \"Binary\",\n",
    "                        \"image_resolution\": {\n",
    "                            \"448x448\": prompt_num #your images size and count\n",
    "                        }\n",
    "                    },\n",
    "                    \"label\": {\n",
    "                        \"label_type\": [\n",
    "                            \"classification\",\n",
    "                            \"seggpt\" # custome label\n",
    "                            \"gradio_seggpt\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"misc\": {\n",
    "                        \"creator\": user_name, \n",
    "                        \"job_id\": 0,\n",
    "                        \"job_name\": \"\",\n",
    "                        \"resize\": \"none\"\n",
    "                    }\n",
    "                    \n",
    "                    \n",
    "                }\n",
    "    )\n",
    "\n",
    "def load_data(project_token):\n",
    "    ds = Dataset()\n",
    "    ret = ds.get_private_dataset(project_token)\n",
    "    return ret\n",
    "\n",
    "def load_and_display(project_token):\n",
    "    print(\"This is the load and display table function\")\n",
    "    print(\"Project token passed in is \" + project_token)\n",
    "    dataset = load_data(project_token)\n",
    "    return create_table(dataset)\n",
    "\n",
    "def create_table(dataset):\n",
    "    print(\"This is the create table function\")\n",
    "    data_list = []\n",
    "    for key, value in dataset.items():\n",
    "        row = {'dateset_token': key}\n",
    "        row.update(value)\n",
    "        if 'versions' in value and len(value['versions']) > 0:\n",
    "            version = value['versions'][0]\n",
    "            metas = version.get('meta', {})\n",
    "            row['Created Time'] = version.get('createdTime',\"None\")\n",
    "            row['Name'] = value.get('name',\"None\")\n",
    "            try:\n",
    "                row['Prompt Image'] = metas['general']['image_count'].get('train')\n",
    "            except:\n",
    "                row['Prompt Image'] = 0\n",
    "            try:\n",
    "                row['Testing Image'] = metas['general']['image_count'].get('test')\n",
    "            except:\n",
    "                row['Testing Image'] = 0\n",
    "            try:\n",
    "                row['Labels'] = ', '.join(metas['label']['label_type']) if 'label_type' in metas['label'] else ''\n",
    "            except:\n",
    "                row['Labels'] = ''\n",
    "            try:\n",
    "                row['Description'] = metas['general'].get('description', '')   \n",
    "            except:\n",
    "                row['Description'] = ''\n",
    "\n",
    "        data_list.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # Select the desired columns in the specified order\n",
    "    desired_columns = ['Created Time', 'Name', 'Prompt Image', 'Testing Image', 'Labels', 'Description']\n",
    "    df = df[desired_columns]\n",
    "\n",
    "    #df = df[df['label_type'].str.contains('seggpt', case=False, na=False)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8689af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package everything into a HDF file\n",
    "\n",
    "def package_images(prompt1, prompt2, prompt3, prompt4, prompt5,prompt6,prompt7,prompt8,prompt9,prompt10, output_file,\n",
    "                    predict_img,prediction_result, answer_mask, performance, description):\n",
    "    prompt_num = 0\n",
    "    predict_img_num = 0 \n",
    "    performance_num = 0\n",
    "    # Create a new HDF5 file\n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        # Create groups and store the image data\n",
    "        prompts = hf.create_group(\"prompts\")\n",
    "        test_set = hf.create_group(\"test_set\")\n",
    "        img = prompts.create_group(\"img\")\n",
    "        mask = prompts.create_group(\"mask\")\n",
    "        pred = test_set.create_group(\"pred\")\n",
    "        pred_ans = test_set.create_group(\"pred_ans\")\n",
    "        pred_img = pred.create_group(\"pred_img\")\n",
    "        pred_result_img = pred.create_group(\"pred_result_img\")\n",
    "        \n",
    "        #pred_result_mask = pred.create_group(\"pred_result_mask\")    \n",
    "        if prompt1:\n",
    "            img.create_dataset('image_1', data=prompt1['image'])\n",
    "            mask.create_dataset('mask_1', data=prompt1['mask'])\n",
    "            print(\"file1\")\n",
    "            prompt_num+=1\n",
    "        if prompt2:    \n",
    "            img.create_dataset('image_2', data=prompt2['image'])\n",
    "            mask.create_dataset('mask_2', data=prompt2['mask'])\n",
    "            print(\"file2\")\n",
    "            prompt_num+=1\n",
    "        if prompt3:\n",
    "            img.create_dataset('image_3', data=prompt3['image'])\n",
    "            mask.create_dataset('mask_3', data=prompt3['mask'])\n",
    "            print(\"file3\")\n",
    "            prompt_num+=1\n",
    "        if prompt4:\n",
    "            img.create_dataset('image_4', data=prompt4['image'])\n",
    "            mask.create_dataset('mask_4', data=prompt4['mask'])\n",
    "            print(\"file4\")\n",
    "            prompt_num+=1\n",
    "        if prompt5:\n",
    "            img.create_dataset('image_5', data=prompt5['image'])\n",
    "            mask.create_dataset('mask_5', data=prompt5['mask'])\n",
    "            print(\"file5\")\n",
    "            prompt_num+=1\n",
    "        if prompt6:\n",
    "            img.create_dataset('image_6', data=prompt6['image'])\n",
    "            mask.create_dataset('mask_6', data=prompt6['mask'])\n",
    "            print(\"file6\")\n",
    "            prompt_num+=1\n",
    "        if prompt7:\n",
    "            img.create_dataset('image_7', data=prompt7['image'])\n",
    "            mask.create_dataset('mask_7', data=prompt7['mask'])\n",
    "            print(\"file7\")\n",
    "            prompt_num+=1\n",
    "        if prompt8:\n",
    "            img.create_dataset('image_8', data=prompt8['image'])\n",
    "            mask.create_dataset('mask_8', data=prompt8['mask'])\n",
    "            print(\"file8\")\n",
    "        if prompt9:\n",
    "            img.create_dataset('image_9', data=prompt9['image'])\n",
    "            mask.create_dataset('mask_9', data=prompt9['mask'])\n",
    "            print(\"file9\")\n",
    "            prompt_num+=1\n",
    "        if prompt10:\n",
    "            img.create_dataset('image_10', data=prompt10['image'])\n",
    "            mask.create_dataset('mask_10', data=prompt10['mask'])\n",
    "            print(\"file10\")\n",
    "            prompt_num+=1\n",
    "        if predict_img.any():\n",
    "            pred_img.create_dataset('pred_img_1', data = predict_img)\n",
    "            predict_img_num +=1\n",
    "            if performance:\n",
    "                pred_img.attrs['performance'] = performance\n",
    "                performance_num += 1\n",
    "                print(\"There is a performance\")\n",
    "            if description:\n",
    "                pred_img.attrs['description'] = description\n",
    "                print(\"There is a description\")\n",
    "        if prediction_result.any():\n",
    "            #pred_result_img.create_dataset('prediction_result_img', data= prediction_result['image'])\n",
    "            #pred_result_mask.create_dataset('prediction_result_mask', data= prediction_result['mask'])\n",
    "            pred_result_img.create_dataset('prediction_result_img', data= prediction_result)\n",
    "        if answer_mask.any():\n",
    "            pred_ans.create_dataset('pred_ans', data = answer_mask)\n",
    "    return prompt_num, predict_img_num, performance_num\n",
    "\n",
    "\n",
    "#Helper Function for packaging and downloading\n",
    "def download_h5_file(prompt1, prompt2, prompt3, prompt4, prompt5,prompt6,prompt7,prompt8,prompt9,prompt10,predict_img,\n",
    "                        prediction_result, answer_mask, performance, description, prompt_name):\n",
    "    # Package the images into an HDF5 file\n",
    "    output_file = prompt_name + '.h5'\n",
    "    prompt_num, predict_img_num, performance_num = package_images(prompt1, prompt2, prompt3, prompt4, prompt5,prompt6,prompt7,prompt8,prompt9,prompt10, output_file, predict_img, prediction_result, answer_mask, performance,description)\n",
    "    return output_file, prompt_num, predict_img_num, performance_num\n",
    "\n",
    "def iterate_h5_file(dataset_filepath,return_id):\n",
    "    prompts_data = {}\n",
    "    prompts_image_data = {}\n",
    "    prompts_mask_data = {}\n",
    "    prediction_results = {}\n",
    "    answers_data = {}\n",
    "    attributes = {}\n",
    "    prediction_image ={}\n",
    "    print(\"Debug0\")\n",
    "    print(file_path)\n",
    "    with h5py.File(dataset_filepath, \"r\") as f:\n",
    "        print(\"Debug1\")\n",
    "        # Extract prompts data\n",
    "        prompts_group = f[\"prompts\"][\"img\"]\n",
    "        masks_group = f[\"prompts\"][\"mask\"]\n",
    "        for key in prompts_group.keys():\n",
    "            image_array = np.array(prompts_group[key])\n",
    "            mask_array = np.array(masks_group[\"mask_\" + key.split(\"_\")[1]])\n",
    "            prompts_data[key] = {\"image\": image_array, \"mask\": mask_array}\n",
    "            prompts_image_data[key] = Image.fromarray(image_array)\n",
    "            prompts_mask_data[key] = Image.fromarray(mask_array)\n",
    "            #prompts_data[key] = {\"image\": Image.fromarray(image_array), \"mask\": Image.fromarray(mask_array)}\n",
    "        #prompt2 = prompts_group[\"image_2\"]\n",
    "        #mask2 = masks_group[\"mask_2\"]\n",
    "        #prompt2 = Image.fromarray(image_array)\n",
    "\n",
    "        # Extract prediction results\n",
    "        prediction_group = f[\"test_set\"][\"pred\"][\"pred_result_img\"]\n",
    "        for key in prediction_group.keys():\n",
    "            prediction_array = np.array(prediction_group[key])\n",
    "            prediction_results[key] = Image.fromarray(prediction_array)\n",
    "\n",
    "        # Extract answers data\n",
    "        answers_group = f[\"test_set\"][\"pred_ans\"]\n",
    "        for key in answers_group.keys():\n",
    "            answer_array = np.array(answers_group[key])\n",
    "            answers_data[key] = Image.fromarray(answer_array)\n",
    "\n",
    "        # Extract attributes\n",
    "        pred_img_group = f[\"test_set\"][\"pred\"][\"pred_img\"]\n",
    "        for key in pred_img_group.keys():\n",
    "            prediction_image_array = np.array(pred_img_group[key])\n",
    "            prediction_image[key] = Image.fromarray(prediction_image_array)\n",
    "            attributes[key] = {}\n",
    "            attributes[key][\"predict_img\"] = np.array(pred_img_group[key])\n",
    "            if \"performance\" in pred_img_group[key].attrs:\n",
    "                attributes[key][\"performance\"] = pred_img_group[key].attrs[\"performance\"]\n",
    "            if \"description\" in pred_img_group[key].attrs:\n",
    "                attributes[key][\"description\"] = pred_img_group[key].attrs[\"description\"]\n",
    "    #prompt2.show()\n",
    "    if return_id==\"prompts_img\":\n",
    "        return prompts_image_data\n",
    "    if return_id==\"prompts_mask\":\n",
    "        return prompts_mask_data\n",
    "    if return_id==\"prediction_results\":\n",
    "        return prediction_results\n",
    "    if return_id==\"answers_data\":\n",
    "        return answers_data\n",
    "    if return_id==\"prediction_image\":\n",
    "        return prediction_image\n",
    "    #return prompts_image_data, prompts_mask_data, prediction_results, answers_data, prediction_image #4,4,1,1\n",
    "    #return prompts_data[\"image_2\"], prediction_results, answers_data, prediction_image, attributes[\"performance\"]\n",
    "    #return prompt2\n",
    "\n",
    "# Example usage\n",
    "#file_path = \"../file.h5\"\n",
    "#prompts_data, prediction_results, answers_data, prediction_image, attributes = iterate_h5_file(file_path)\n",
    "\n",
    "    \n",
    "def load_prompts_img(file_path):\n",
    "    x = \"prompts_img\"\n",
    "    prompts_data_list = iterate_h5_file(file_path,x)\n",
    "    updates = [gr.ImageMask.update(value=prompts_data_list[prompt_image], visible=True) for prompt_image in prompts_data_list]\n",
    "    updates += [gr.ImageMask.update(value=None, visible=False)] * (10 - len(prompts_data_list))\n",
    "    print(\"DEBUG\")\n",
    "    return updates\n",
    "\n",
    "def load_mask_img(file_path):\n",
    "    x = \"prompts_mask\"\n",
    "    prompts_mask_list = iterate_h5_file(file_path,x)\n",
    "    updates = [gr.Image.update(value=prompts_mask_list[prompt_mask], visible = True) for prompt_mask in prompts_mask_list]\n",
    "    updates += [gr.Image.update(value=None, visible=False)] * (10 - len(prompts_mask_list))\n",
    "    return updates\n",
    "\n",
    "def load_pred_results(file_path):\n",
    "    x = \"prediction_results\"\n",
    "    output_list = iterate_h5_file(file_path,x)\n",
    "    output_list[\"prediction_result_img\"].show()\n",
    "    updates = gr.Image.update(value=output_list[\"prediction_result_img\"], visible=True)\n",
    "    \n",
    "    return updates\n",
    "\n",
    "def load_answer(file_path):\n",
    "    x = \"answers_data\"\n",
    "    output_list = iterate_h5_file(file_path,x)\n",
    "    updates = gr.Image.update(value=output_list[\"pred_ans\"], visible=True)\n",
    "\n",
    "    return updates\n",
    "\n",
    "def load_pred_img(file_path):\n",
    "    x = \"prediction_image\"\n",
    "    output_list = iterate_h5_file(file_path,x)\n",
    "    updates = gr.Image.update(value=output_list[\"pred_img_1\"], visible=True)\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33753d5",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "demo_title = \"<div style = 'text-align: center;margin: 50px auto;padding: 20px;max-width: 1000px;background-color: #ffffff;box-shadow: 0px 0px 20px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 60px;font-weight: bold;color: #003366;text-shadow: 2px 2px 4px #cccccc;'>Inference-Based Defect Detection</h1>\\\n",
    "<div style = 'font-size: 24px;color: #333333;line-height: 1.6;max-width: 800px;margin: 0 auto;'> By implementing a defect detection AI model on the production line, we aim to streamline operations and improve quality control. Our goals include reducing missing and false reports, cutting down on human resources, and simplifying the overall working process.</div> \\\n",
    "<div style='font-size: 18px;color: #666666;line-height: 1.6;max-width: 800px;margin: 30px auto;'>UI allows users to upload images, labeled or unlabeled, perform defect detection, and report performance given the ground truth.</div> \\\n",
    "</div>\\\n",
    "\" \n",
    "upload_prompt_title = \"<div style = 'text-align: center;margin: 35px auto;padding: 20px;max-width: 800px;background-color: #ffffff;box-shadow: 0px 2px 6px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 35px;font-weight: bold;margin-bottom: 16px;color: #003366;'>Upload Prompt</h1>\\\n",
    "<div style = 'text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 16px;'> 1. Slide to choose the amount of prompt you want to upload </div> \\\n",
    "<div style='text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 20px;'>2. Label your prompts</div> \\\n",
    "</div>\\\n",
    "\"\n",
    "\n",
    "upload_predict_image_title = \"<div style = 'text-align: center;margin: 35px auto;padding: 20px;max-width: 800px;background-color: #ffffff;box-shadow: 0px 2px 6px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 35px;font-weight: bold;margin-bottom: 16px;color: #003366;'>Image Prediction and Evaluation</h1>\\\n",
    "<div style = 'text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 16px;'> 1. Upload your image for prediction </div> \\\n",
    "<div style='text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 20px;'>2. Upload the labeled mask and Evaluate Performance</div> \\\n",
    "</div>\\\n",
    "\"\n",
    "\n",
    "save_prompt_title = \"<div style = 'text-align: center;margin: 35px auto;padding: 20px;max-width: 800px;background-color: #ffffff;box-shadow: 0px 2px 6px rgba(0, 0, 0, 0.1);border-radius: 10px;color: #333333;'> \\\n",
    "<h1 style = 'font-size: 35px;font-weight: bold;margin-bottom: 16px;color: #003366;'>Save Prompts</h1>\\\n",
    "<div style = 'text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 16px;'> 1. Enter your filename and save your prompt </div> \\\n",
    "<div style='text-align: left;font-size: 20px;line-height: 1.6;margin-bottom: 20px;'>2. Check your saved prompt in 'Saved Prompt' tab </div> \\\n",
    "</div>\\\n",
    "\"\n",
    "css = \"\"\"\n",
    ".imageItem {\n",
    "min-width: 450px !important;\n",
    "max-width: 450px !important;\n",
    "}\n",
    "\n",
    ".svelte-yigbas {\n",
    "width: 100% !important;\n",
    "height: 100% !important;\n",
    "object-fit: contain !important;\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "project_info_list = []\n",
    "\n",
    "#Determine Maximum Amount of Prompts\n",
    "max_imagebox = 10\n",
    "\n",
    "saved_prompts = []\n",
    "\n",
    "def changetabtoprompt():\n",
    "    print(\"hi\")\n",
    "    return gr.Tabs.update(selected = 'tab1')\n",
    "\n",
    "\n",
    "def return_path():\n",
    "    path = \"../file.h5\"\n",
    "    return path\n",
    "\n",
    "def showtabs():\n",
    "    print(\"TABBBB\")\n",
    "    return gr.Row.update(visible = True)\n",
    "def wait():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a1958",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with gr.Blocks(css =css) as demo:\n",
    "    user_name = gr.State('None')\n",
    "    project_options = gr.State([])\n",
    "    project_info_list = gr.State([])\n",
    "    project_token = gr.State('')\n",
    "    dataset_file_path = gr.State('')\n",
    "    demo.load(fn = return_path, outputs = dataset_file_path )\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale =7):\n",
    "            gr.Markdown(demo_title)\n",
    "        with gr.Column(scale =1):\n",
    "            user_name_display = gr.Text(label=\"user_name\")\n",
    "            project_dropdown = gr.Dropdown(project_options.value, label='Project Names', interactive=True)\n",
    "            project_token_display = gr.Text(label=\"project_token\", visible = False)\n",
    "            dataset_token_display = gr.Text(label=\"dataset_token\", visible = False)\n",
    "    demo.load(\n",
    "        fn=get_user_name,\n",
    "        inputs=[],\n",
    "        outputs=[user_name, user_name_display]\n",
    "    )\n",
    "    demo.load(\n",
    "        fn=get_projects,\n",
    "        inputs=[user_name],\n",
    "        outputs=[project_dropdown, project_info_list]\n",
    "    )\n",
    "\n",
    "    project_dropdown.change(\n",
    "        fn=show_project_token,\n",
    "        inputs=[project_dropdown],\n",
    "        outputs=[project_token_display]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(user_name)\n",
    "    print(project_info_list)\n",
    "\n",
    "    \n",
    "    gr.Markdown(\"<br>\\\n",
    "                <br>\\\n",
    "                \")\n",
    "    with gr.Row(visible = False) as main_row:\n",
    "        project_dropdown.select(showtabs, outputs= main_row)\n",
    "        with gr.Tabs() as main_tab:\n",
    "            with gr.Tab(\"Prompting and Predicting\", id = 'tab1') as prompting:\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\n",
    "                            upload_prompt_title\n",
    "                        )\n",
    "\n",
    "                with gr.Row():\n",
    "                    slider = gr.Slider(1,max_imagebox, step = 1, value = 10, label = \"Amount of Prompts: \",scale=5)\n",
    "                    prompt_button = gr.Button(value = \"Enter\",scale = 1)                \n",
    "                with gr.Row():    \n",
    "                    imagebox = []\n",
    "                    for i in range(max_imagebox):\n",
    "\n",
    "                        masked_image = gr.ImageMask(brush_radius=16, label = \"Prompt\", elem_classes='imageItem', scale = 1)\n",
    "\n",
    "                        imagebox.append(masked_image)\n",
    "                with gr.Row():\n",
    "                    gr.Markdown(upload_predict_image_title)        \n",
    "                with gr.Row():\n",
    "                    '''\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"# Upload Hdf5 File For Prediction\")\n",
    "                        test_file = gr.File(Label = \"Upload Hdf5 File for Prediction\")\n",
    "                        test_evaluation = gr.Button('Evaluate Performance')\n",
    "                        test_performance = gr.Textbox(label = \"Performance(Dice Coefficient)\")   \n",
    "                    '''\n",
    "                    with gr.Column():\n",
    "                        with gr.Row():\n",
    "                            with gr.Column():\n",
    "                                gr.Markdown(\"# Upload Photo for Prediction\")\n",
    "                                predict_img = gr.Image(shape=(240, 240),label = \"Predict Image\")\n",
    "                                predict_button = gr.Button('Predict')\n",
    "                                #clear_prompt_button = gr.ClearButton(imagebox, value = 'Clear All Prompt')\n",
    "                                #clear_image_button = gr.ClearButton(predict_img, value = 'Clear Predict Image')\n",
    "\n",
    "                                prediction_result = gr.Image(label = \"Prediction Result\", interactive = False)\n",
    "\n",
    "\n",
    "                    with gr.Column():\n",
    "                        with gr.Row():\n",
    "                            with gr.Column():\n",
    "                                gr.Markdown(\"# <br>\\\n",
    "                                            \")\n",
    "                                answer_mask = gr.Image(label = \"Labeled Answer\")\n",
    "                                evaluate_button = gr.Button('Evaluate Performance')\n",
    "                                performance = gr.Textbox(label = \"Performance(Dice Coefficient)\",interactive = False)   \n",
    "                with gr.Row():\n",
    "                    gr.Markdown(save_prompt_title)     \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        prompt_name = gr.Textbox(label = \"Prompt Name\")\n",
    "                        prompt_desc = gr.Textbox(label = \"Description\")\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Text(visible=False)\n",
    "                    with gr.Column():\n",
    "                        with gr.Row():\n",
    "                            save_file_button = gr.Button('Save Prompt')\n",
    "                    with gr.Column():\n",
    "                        gr.Text(visible=False)    \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        output_file = gr.File(interactive = False)\n",
    "\n",
    "                    evaluate_button.click(evaluate_function, answer_mask, performance)      \n",
    "\n",
    "        #SLIDE THEN CLICK TO CHANGE\n",
    "                    prompt_button.click(variable_outputs, slider, imagebox)\n",
    "        #SLIDE AND CHANGE IMMEDIATELY\n",
    "                    #slider.change(variable_outputs, slider, imagebox)\n",
    "\n",
    "                    print(imagebox)\n",
    "                    #predict_button.click(demo_function, inputs= [imagebox, predict_img], outputs=prediction_result)\n",
    "                    predict_button.click(demo_function2, inputs= [imagebox[0], imagebox[1],imagebox[2],imagebox[3],imagebox[4],imagebox[5],imagebox[6],imagebox[7],imagebox[8],imagebox[9], predict_img], outputs=[prediction_result])\n",
    "                    #load_button.click()\n",
    "                    prompt_num = gr.State('')\n",
    "                    predict_img_num = gr.State('')\n",
    "                    performance_num = gr.State('')\n",
    "                    file_path = gr.State('')\n",
    "                    save_file_button.click(download_h5_file, inputs= [imagebox[0], imagebox[1],imagebox[2],imagebox[3],imagebox[4],imagebox[5],imagebox[6],imagebox[7],imagebox[8],imagebox[9],\n",
    "                                                     predict_img,prediction_result, answer_mask, performance,prompt_desc,prompt_name], outputs = [output_file,prompt_num,predict_img_num, performance_num]).then(fn = wait).then(save_data, \n",
    "                                                     inputs = [user_name, file_path, project_token_display, prompt_name,prompt_num,predict_img_num,performance_num,prompt_desc])\n",
    "                    \n",
    "                    \n",
    "                    output_file.change(get_path, inputs = [output_file], outputs = file_path)  \n",
    "                    \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"<br>\\\n",
    "                        <br>\\\n",
    "                        \")\n",
    "                        gr.Markdown(\"## Test Examples\")\n",
    "                        gr.Examples(\n",
    "                            examples = examples,\n",
    "                            inputs = imagebox,\n",
    "                            cache_examples = False,\n",
    "                        )\n",
    "                        gr.Markdown(\"## Prediction Examples\")\n",
    "                        gr.Examples(\n",
    "                            examples = examples_pred,\n",
    "                            inputs = predict_img,\n",
    "                            cache_examples = False,\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "            with gr.Tab(\"Saved Prompt\", id = 'tab2') as loading:\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\n",
    "                                    #title\n",
    "                                    \"\"\"\n",
    "                                    # THIS PAGE SHOWS ALL THE SAVED VERSION\n",
    "                                    # Add a chart that shows entire chart\n",
    "                                    # Add a dropdown\n",
    "                                    \"\"\"\n",
    "                                ) \n",
    "\n",
    "                with gr.Row():\n",
    "                    table = gr.Dataframe(interactive = False)\n",
    "                    #load_and_display\n",
    "\n",
    "        #        table.change(load_and_display, inputs=[project_token_display],outputs=[table])\n",
    "                project_token_display.change(\n",
    "                    fn=load_and_display,\n",
    "                    inputs=[project_token_display],\n",
    "                    outputs=[table]\n",
    "                )    \n",
    "                with gr.Row():\n",
    "                    gr.Markdown(\n",
    "                                    #title\n",
    "                                    \"\"\"\n",
    "                                    # Load Model Blahblahblah\n",
    "                                    \"\"\"\n",
    "                                )\n",
    "                data_options = gr.State([])\n",
    "                with gr.Row():\n",
    "                    load_dropdown = gr.Dropdown(data_options.value, label='Datasets Names', interactive=True)\n",
    "\n",
    "                project_token_display.change(\n",
    "                    fn=show_all_dataset,\n",
    "                    inputs=[project_token_display],\n",
    "                    outputs=[load_dropdown]\n",
    "                )  \n",
    "\n",
    "\n",
    "                load_dropdown.change(\n",
    "                    fn=show_dataset_token,\n",
    "                    inputs=[load_dropdown],\n",
    "                    outputs=[dataset_token_display]\n",
    "                )\n",
    "\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Text(visible=False)\n",
    "                    with gr.Column():\n",
    "                        load_button = gr.Button(\"Load Button\")\n",
    "\n",
    "                    with gr.Column():\n",
    "                        gr.Text(visible=False)\n",
    "\n",
    "                #load_button.click(get_data, inputs = [dataset_token_display, project_token_display])\n",
    "                load_button.click(changetabtoprompt, outputs = main_tab)\n",
    "\n",
    "                load_button.click(fn=load_prompts_img,inputs= dataset_file_path, outputs=imagebox)        \n",
    "                #load_button.click(fn=load_mask_img,inputs= file_path, outputs=mask_img_list)\n",
    "                load_button.click(fn=load_pred_img, inputs=dataset_file_path, outputs=predict_img)\n",
    "                load_button.click(fn=load_answer, inputs=dataset_file_path, outputs=answer_mask)\n",
    "                load_button.click(fn=load_pred_results, inputs=dataset_file_path, outputs=prediction_result)\n",
    "                #temp_button.click(read_h5_file, outputs = [each_data,another_data])\n",
    "\n",
    "                #gr.load(load_and_display, inputs =project_token_display, outputs = table)        \n",
    "                #load_button.click(function, inputs, outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch(enable_queue=True, server_name=\"0.0.0.0\",server_port=6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4424bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
